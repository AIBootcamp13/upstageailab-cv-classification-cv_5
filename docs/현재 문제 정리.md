## 🚨 **팀장님 지적사항 정리**

### **현재 문제 (Baseline_noaugment.ipynb)**

1. **과적합 심함**: 15 epoch만에 train_loss 0.0004로 급속 수렴
2. **Validation accuracy 높음**: 증강 안된 validation이 test보다 쉬워 보임
3. **Validation 시 augmentation 필요**: Test 환경과 동일하게 만들어야 함
4. **우선순위**: 모델 실험 < **증강/검증/TTA/시각화 분석**

### 지금 참가 중인 **문서 이미지 분류 대회**에서 **데이터 증강(Augmentation)**, **Validation 전략**, **Test Time Augmentation**, **시각화 및 분석**이 **왜 중요한지**는 다음과 같은 **명확한 근거**와 **문제 특성에 기반한 이유** 때문입니다:

## ✅ 왜 이런 전략이 중요한가? — 문제 특성 기반 분석

### 1. **테스트 데이터의 실제 분포와 노이즈 문제**

> ✔️ “평가 데이터는 학습 데이터와 달리 회전, Flip, 훼손된 이미지가 존재합니다.”
> 
- 즉, **train 데이터는 깔끔하고 정중앙**에 문서가 있는 반면,
- **test 데이터는 회전되거나 찢겨있거나 그림자가 진** 등의 상황이 많습니다.

📌 따라서 학습 시에도 **이런 상황을 시뮬레이션할 수 있는 Augmentation**이 꼭 필요합니다.

### ➤ 사용해야 할 증강 이유 정리:

| Augmentation 기법 | 이유 | 관련 문제 대응 |
| --- | --- | --- |
| `RandomRotation`, `RandomResizedCrop` | test 데이터가 회전·확대/축소되어 있음 | 시야 각도와 크기 변형 대응 |
| `ColorJitter`, `RandomShadow` | 그림자, 조명 차이 | 다양한 조도에 대한 강건함 확보 |
| `RandomPerspective`, `Affine` | 왜곡, 찢김 대응 | test 이미지 훼손 대응 |
| `Cutout`, `MixUp`, `CutMix` | 신분증/계좌번호 등 민감 정보 마스킹 → 실제 마스크 영역 존재 | 마스킹된 영역 보완 (정보 손실에 강한 모델 훈련) |

📌 **출처**: Upstage CV Classification 대회 설명 + `Albumentations` 공식 증강 사례 문서

https://albumentations.ai/docs/examples/example_kaggle_salt/

---

### 2. **문서 종류 간의 시각적 유사성 문제**

> 일부 문서 (예: 주민등록증, 운전면허증, 여권) 는 겉보기에 매우 유사
> 
- 학습 데이터가 작고 클래스 간 시각적 차이가 미미한 경우가 많음
- 증강을 통해 **데이터 다양성 확보 = 모델이 과적합되지 않고 일반화**

📌 **참고 논문**:

**Perez & Wang (2017), "The Effectiveness of Data Augmentation in Image Classification using Deep Learning"**

→ 증강을 사용하지 않은 모델은 거의 대부분 과적합됨

https://arxiv.org/abs/1712.04621

---

### 3. **Validation 데이터도 실제 Test 환경과 유사해야 함**

> 단순히 train을 8:2로 나눠 쓰면, 깨끗한 validation set → 실제 test 성능 예측 실패
> 

📌 그래서 필요한 전략:

- `Stratified K-Fold` → 클래스별 분포 유지
- `증강된 validation set` → 실제 test set과 유사한 환경 시뮬레이션

📌 **근거 논문**:

**Buda et al., “A systematic study of the class imbalance problem in convolutional neural networks” (2018)**

https://arxiv.org/abs/1710.05381

---

### 4. **Test Time Augmentation (TTA)**

> TTA는 모델이 하나의 이미지에 대해 다양한 시점/조명/각도에서 추론하여 예측의 안정성과 정확도 향상
> 
- 일반적인 모델은 한 번만 이미지를 본다.
- TTA를 적용하면 같은 이미지를 5~10가지 각도·색상 등으로 변형해 예측 후 평균 → 더 정확한 예측

📌 **근거 논문**:

**Wang et al., "Better Aggregation in Test-Time Augmentation for Image Classification" (ICCV 2021)**

https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Better_Aggregation_in_Test-Time_Augmentation_for_Image_Classification_ICCV_2021_paper.pdf

---

### 5. **시각화를 통한 오류 분석 및 약점 보완**

> Grad-CAM, Confusion Matrix, 실패 예시 시각화
> 
- 모델이 진짜 **문서 주요 부위(예: 제목, 마크, 로고)**에 주목하고 있는지 확인 가능
- 잘못 분류된 케이스를 보면 "이런 케이스엔 왜 약하지?" 파악 → 다음 실험 전략 수립에 도움

📌 실제 경진대회에서 수상자 전략 중 가장 중요한 단계 중 하나

**출처**: https://www.kaggle.com/code/sreevishnudamodaran/image-classification-visualization-gradcam

---

## 요약: 왜 이 전략들이 필수인가?

| 전략 | 이유 | 실제 효과 |
| --- | --- | --- |
| 이미지 증강 | Test 데이터의 회전/훼손/마스킹 대응 | 일반화 성능 증가 |
| K-Fold + 증강 Validation | 실제 Test와 유사한 평가 환경 | 모델 튜닝 정확도 증가 |
| Test-Time Augmentation | 다양한 변형된 시점에서 예측 | 예측 안정성/정확도 향상 |
| Grad-CAM 등 시각화 | 왜 오답이 발생했는지 분석 | 모델의 주의 영역 개선 |

---

### 📌 결론

> 이 전략들은 단순 성능 향상을 넘어서, 문서 이미지의 실제 문제 상황을 반영하여 모델이 잘못 배울 가능성을 줄이고, 테스트 데이터처럼 변형된 상황에서도 올바른 예측을 하도록 돕는 핵심 요소입니다.
>

# ✔️ 데이터 증강 > Validation 전략 > TTA > 모델 분석이 문서 이미지 분류에서 가장 중요한 순서

## 데이터 증강 전략

### **문서 이미지의 특수성**

1. **일반 이미지 vs 문서 이미지의 차이**
    - 일반 이미지: 자연 풍경, 사물, 사람 등
    - 문서 이미지: 텍스트, 표, 서명, 도장 등의 **구조화된 정보**
2. **현실적인 문서 왜곡 시뮬레이션**
    - Albumentations: 카메라 촬영 환경의 일반적 변형
    - Augraphy: **프린터→스캐너→팩스** 등 실제 사무 환경 왜곡
3. **상현님이 관찰한 테스트 데이터 특성과 일치**
    - "Test 데이터는 회전한게 많고, 종이 모서리 부분을 자른게 많아 보임"
        
        ⇒ 이는 Augraphy가 시뮬레이션하는 **사무실 문서 처리 과정**입니다
        
    
    ### **Augraphy 관련 링크:**
    
    https://arxiv.org/abs/2208.14558
    
    논문 요역: https://lilys.ai/digest/4795331/4018635
    
    → “Augraphy는 사실적인 노이즈를 모방하여 스캔, 복사 등 문서 작업에서 발생하는 왜곡과 손상 효과를 재현하는 도구로서, 기존 이미지 증강 툴과 차별화된다”
    
    ### **2. 회전 문제 해결 관련:**
    
    - **Data Augmentation Survey (PMC)**: https://pmc.ncbi.nlm.nih.gov/articles/PMC9966095/
    
    ### **3. 증강 조합 전략 관련:**
    
    - **Journal of Big Data**: https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0
    
    ## 💡 **실제 추천: 하이브리드 접근법**
    
    사실 **Albumentations + Augraphy 조합**이 가장 효과적일 것입니다:
    
    ```python
    # 1단계: Albumentations (기본 증강)
    import albumentations as A
    
    basic_transforms = A.Compose([
        A.RandomRotate90(p=0.5),
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.3),
        A.RandomCrop(height=800, width=600, p=0.5)
    ])
    
    # 2단계: Augraphy (문서 특화 증강)
    import augraphy as ag
    
    document_pipeline = ag.AugraphyPipeline(
        ink_phase=[ag.InkBleed(), ag.InkShifter()],
        paper_phase=[ag.PaperFactory(), ag.ColorPaper()],
        post_phase=[ag.DirtyDrum(), ag.SubtleNoise()]
    )
    ```
    
    ## **결론**
    
    Augraphy를 추천한 이유는 **문서 이미지 특화** 때문이지만, 말씀하신 대로 Albumentations가 더 검증된 라이브러리입니다.
    
    **최적 전략**:
    
    1. **Albumentations를 메인**으로 사용
    2. **Augraphy를 보조**로 활용 (문서 특화 노이즈용)
    3. 팀의 GPU 리소스와 시간을 고려하여 선택
    
    팀장님 판단에 따라 Albumentations부터 시작하시는 것도 충분히 좋은 전략입니다!

### **과적합 해결**

- [ ]  PetFinder 방식 Layer-wise 모델 구현
- [ ]  Out-of-fold validation 적용
- [ ]  Performance gap 모니터링 시스템 구축

### **Validation 개선**

- [ ]  Bengali.AI 방식 Test-like validation 구현
- [ ]  Clean vs Augmented validation 성능 비교
- [ ]  팀원 관찰사항 반영한 augmentation 적용

### **TTA & 최적화**

- [ ]  적응적 TTA 파이프라인 구현
- [ ]  문서 특화 TTA 전략 적용
- [ ]  최종 성능 및 시각화 분석

**예상 개선 효과**: Train loss 정상화 + Test 성능 5-10% 향상