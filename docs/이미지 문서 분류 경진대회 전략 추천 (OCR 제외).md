# 이미지 문서 분류 경진대회 전략 추천 (OCR 제외)

OCR을 사용하지 않고 이미지 자체의 시각적 특징만으로 17개 클래스를 분류해야 하며, 테스트 데이터에 다양한 증강이 적용되어 있다는 점을 고려하면 **강력한 이미지 특징 추출 능력과 다양한 변형에 강인한 모델**을 만드는 것이 핵심입니다.

### 1. 데이터 전처리 및 증강 (가장 중요!)

테스트 데이터에 다양한 증강이 적용되어 있다는 것은, 모델이 단순히 트레인 데이터에만 최적화되면 안 되고, **다양한 변형을 포괄적으로 이해할 수 있어야 한다는 강력한 신호**입니다.

- **학습 데이터 증강:** 트레인 데이터가 '정상적'이라고 해도, 테스트 데이터의 증강 유형을 예측하여 **학습 데이터에도 동일하거나 유사한 증강 기법을 적극적으로 적용**해야 합니다.
    - **기하학적 변형:** 회전 (작은 각도부터 큰 각도까지), 이동, 스케일링, 수평/수직 뒤집기 (문서 내용에 따라 신중하게 적용), **약간의 시어(shear) 또는 워프(warp) 변형**을 통해 문서가 찌그러지거나 기울어진 상황을 모방합니다.
    - **색상 및 밝기 변형:** 밝기, 대비, 채도 조절 (jittering), 그레이스케일 변환 등을 통해 스캔 환경의 변화를 시뮬레이션합니다.
    - **노이즈 추가:** 스캔 과정에서 발생할 수 있는 가우시안 노이즈, 스펙클 노이즈 등을 추가합니다.
    - **블러링(Blurring):** 모션 블러, 가우시안 블러 등을 적용하여 실제 스캔본의 흐릿함을 모방합니다.
    - **CutMix 또는 Mixup:** 이미지의 일부를 잘라내 다른 이미지의 일부와 섞거나 (CutMix), 이미지 픽셀 값을 선형 결합하여 (Mixup) 모델의 일반화 성능을 높일 수 있습니다. 이는 모델이 부분적인 정보만으로도 분류를 수행하도록 훈련시킵니다.
- **전처리:** 모든 이미지를 모델 입력에 맞게 **일정한 크기로 리사이즈**하고, 픽셀 값을 0~1 또는 -1~1 범위로 **정규화**합니다. 이미지 크기 선정 시, 문서의 주요 레이아웃 특징을 보존할 수 있도록 너무 작게 리사이즈하지 않는 것이 좋습니다.

### 2. 강력한 이미지 특징 추출 모델 (CNN 기반)

OCR 정보 없이 시각적 특징만 활용해야 하므로, **강력한 CNN 기반 모델**을 사용하는 것이 필수적입니다.

- **사전 학습된 모델 (Pre-trained Models):** ImageNet과 같은 대규모 데이터셋으로 사전 학습된 모델을 활용하는 것이 가장 효과적입니다.
    - **ResNet 계열 (ResNet50, ResNet101, ResNeXt):** 안정적이고 성능이 검증된 모델입니다.
    - **EfficientNet 계열 (EfficientNet B0-B7):** 모델 크기와 성능의 균형이 뛰어나 다양한 환경에서 좋은 성능을 보입니다.
    - **ConvNeXt:** 최신 CNN 아키텍처로, 트랜스포머의 장점을 CNN에 녹여낸 모델입니다.
    - **ViT (Vision Transformer) 계열 (Swin Transformer, DeiT):** 이미지 분류에서 강력한 성능을 보이는 트랜스포머 기반 모델도 고려할 수 있습니다. 특히 다양한 스케일의 특징을 잘 포착할 수 있는 **Swin Transformer**가 문서 이미지처럼 구조적인 특징이 중요한 경우 유리할 수 있습니다.
- **전이 학습 (Transfer Learning) 및 미세 조정 (Fine-tuning):**
    - 사전 학습된 모델의 마지막 분류 레이어만 교체하여 학습시키는 것부터 시작하고, 성능이 충분하지 않다면 모델의 더 많은 레이어를 데이터셋에 맞게 미세 조정하는 전략을 사용합니다.
    - 문서 이미지 특성상, 일반적인 자연 이미지와는 다른 특징(텍스처, 레이아웃 등)이 중요할 수 있으므로, **초기 컨볼루션 레이어까지도 미세 조정**하는 것이 유리할 수 있습니다.

### 3. 학습 전략 최적화

- **옵티마이저:** **AdamW** (L2 정규화와 함께 Adam을 사용하는 것으로, Weight Decay가 더 잘 작동함) 또는 SGD with Momentum을 사용합니다.
- **학습률 스케줄러:** **Cosine Annealing Warm Restarts** 또는 **One Cycle LR**과 같이 학습률을 동적으로 조정하는 스케줄러를 사용하여 학습 초기 안정성과 최종 수렴 성능을 높입니다.
- **손실 함수:** **Label Smoothing Cross Entropy**를 고려해 보세요. 이는 하드 레이블 대신 부드러운 레이블을 사용하여 모델의 과신을 방지하고 일반화 성능을 향상시키는 데 도움이 됩니다.
- **배치 크기:** GPU 메모리 한도 내에서 최대한 큰 배치 크기를 사용하는 것이 학습 효율성에 도움이 될 수 있습니다.
- **정규화:** 드롭아웃(Dropout)을 적절히 사용하고, **모델의 오버피팅을 방지**하기 위해 Early Stopping을 적용합니다.

### 4. 앙상블 (Ensemble)

다양한 변형이 적용된 테스트 데이터에서 안정적인 성능을 확보하기 위해 **앙상블은 거의 필수적인 전략**입니다.

- **모델 아키텍처 다양화:** ResNet, EfficientNet, ConvNeXt 등 **서로 다른 아키텍처의 모델들을 학습**시킨 후 예측 결과를 결합합니다.
- **동일 아키텍처, 다른 학습:** 같은 모델이라도 **다른 초기 가중치, 다른 데이터 증강 시드, 또는 다른 학습률 스케줄러**로 여러 번 학습시켜 앙상블합니다.
- **예측 결합 방식:**
    - **소프트 보팅 (Soft Voting):** 각 모델의 최종 예측 확률(logit 또는 softmax 출력)을 평균하여 최종 예측을 결정합니다. 일반적으로 가장 효과적인 방법 중 하나입니다.
    - **가중 평균 (Weighted Averaging):** 교차 검증 성능에 따라 각 모델에 가중치를 부여하여 예측을 결합합니다.

---

### 요약 및 추천 전략

1. **데이터 증강을 핵심으로 삼으세요:** 테스트 데이터의 증강 유형을 최대한 파악하고, 학습 데이터에도 이를 적극적으로 적용하여 모델이 다양한 변형에 강인하도록 훈련하세요. **Albumentations** 라이브러리를 사용하면 다양한 이미지 증강 기법을 쉽게 적용할 수 있습니다.
2. **강력한 사전 학습된 CNN 모델 활용:** EfficientNet, ConvNeXt, 또는 Swin Transformer와 같이 최신이면서 성능이 검증된 모델을 선택하고, 충분한 미세 조정을 통해 문서 이미지 특징에 최적화하세요.
3. **앙상블은 선택이 아닌 필수:** 여러 모델을 조합하여 안정적이고 높은 성능을 달성하세요.