# CV-Classify ëª¨ë“ˆ ì°¸ì¡° ë¬¸ì„œ

## ğŸ“‹ ê°œìš”

CV-Classify ì‹œìŠ¤í…œì˜ ì£¼ìš” Python ëª¨ë“ˆë“¤ì— ëŒ€í•œ ìƒì„¸í•œ API ì°¸ì¡° ë¬¸ì„œì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì˜ ê¸°ëŠ¥, í´ë˜ìŠ¤, í•¨ìˆ˜, ì‚¬ìš© ì˜ˆì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ“‚ ëª¨ë“ˆ êµ¬ì¡°

```
codes/
â”œâ”€â”€ config.py           # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ device_utils.py     # ë””ë°”ì´ìŠ¤ ìµœì í™”
â”œâ”€â”€ wandb_utils.py      # ì‹¤í—˜ ì¶”ì 
â”œâ”€â”€ baseline_simple.py  # ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸
â”œâ”€â”€ train_with_wandb.py # ê³ ê¸‰ ì‹¤í—˜ ì‹¤í–‰
â””â”€â”€ train_with_ocr.py   # OCR í†µí•© ëª¨ë¸
```

---

## ğŸ”§ config.py

**ìš©ë„**: ì „ì²´ ì‹œìŠ¤í…œì˜ ì„¤ì •ì„ ì¤‘ì•™ ì§‘ì¤‘ì‹ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ëª¨ë“ˆ

### ì£¼ìš” ì„¤ì • ê°ì²´

#### `WANDB_CONFIG`
WandB ì‹¤í—˜ ì¶”ì  ê´€ë ¨ ì„¤ì •

```python
WANDB_CONFIG = {
    "api_key": os.getenv("WANDB_API_KEY"),
    "project": os.getenv("WANDB_PROJECT", "cv-classification"),
    "entity": os.getenv("WANDB_ENTITY"),
    "mode": os.getenv("WANDB_MODE", "online"),
    "tags": ["cv", "classification", "document", "upstage"]
}
```

**ì‚¬ìš© ì˜ˆì œ**:
```python
from config import WANDB_CONFIG
import wandb

# WandB ì´ˆê¸°í™”
wandb.init(
    project=WANDB_CONFIG["project"],
    tags=WANDB_CONFIG["tags"]
)
```

#### `EXPERIMENT_CONFIG`
ê³ ê¸‰ ì‹¤í—˜ìš© ì„¤ì • (ì‹¤ì œ ê²½ì§„ëŒ€íšŒìš©)

```python
EXPERIMENT_CONFIG = {
    # ëª¨ë¸ ì„¤ì •
    "model_name": "resnet34",
    "num_classes": 17,
    "pretrained": True,
    
    # í•™ìŠµ ì„¤ì •
    "img_size": 224,
    "batch_size": 32,
    "learning_rate": 1e-3,
    "epochs": 50,
    "num_workers": 4,
    
    # ë°ì´í„° ì¦ê°•
    "augmentation": {
        "horizontal_flip": True,
        "vertical_flip": False,
        "rotation": 15,
        "brightness": 0.2,
        "contrast": 0.2,
    },
    
    # ì¡°ê¸° ì¢…ë£Œ
    "early_stopping": {
        "enabled": True,
        "patience": 10,
        "min_delta": 0.001,
    }
}
```

#### `BASELINE_CONFIG`
ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸ìš© ì„¤ì • (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)

```python
BASELINE_CONFIG = {
    "model_name": "resnet34",
    "num_classes": 17,
    "pretrained": True,
    "img_size": 32,        # ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‘ì€ ì´ë¯¸ì§€
    "batch_size": 32,
    "learning_rate": 1e-3,
    "epochs": 1,           # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
    "num_workers": 0,
    "enable_macos_optimization": True,
    "compatibility_mode": False
}
```

#### `DATA_CONFIG`
ë°ì´í„° ê²½ë¡œ ë° ë¶„í•  ì„¤ì •

```python
DATA_CONFIG = {
    "train_csv": str(DATA_DIR / "train.csv"),
    "test_csv": str(DATA_DIR / "sample_submission.csv"),
    "train_dir": str(DATA_DIR / "train"),
    "test_dir": str(DATA_DIR / "test"),
    "submission_dir": str(DATA_DIR / "submissions"),
    "val_split": 0.2,
    "stratify": True,
    "random_seed": 42
}
```

### ì£¼ìš” í•¨ìˆ˜

#### `get_wandb_config() -> Dict[str, Any]`
WandB ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ì„¤ì • ë°˜í™˜

**ë°˜í™˜ê°’**: WandB ì´ˆê¸°í™”ì— í•„ìš”í•œ ì„¤ì • ë”•ì…”ë„ˆë¦¬

**ì‚¬ìš© ì˜ˆì œ**:
```python
from config import get_wandb_config
from wandb_utils import init_wandb

config = get_wandb_config()
run = init_wandb(config, run_name="my_experiment")
```

#### `get_experiment_name(model_name: str = None, additional_info: str = None) -> str`
ì‹¤í—˜ ì´ë¦„ ìë™ ìƒì„±

**ë§¤ê°œë³€ìˆ˜**:
- `model_name`: ëª¨ë¸ ì´ë¦„ (ì„ íƒì‚¬í•­)
- `additional_info`: ì¶”ê°€ ì •ë³´ (ì„ íƒì‚¬í•­)

**ë°˜í™˜ê°’**: ìƒì„±ëœ ì‹¤í—˜ ì´ë¦„

**ì‚¬ìš© ì˜ˆì œ**:
```python
from config import get_experiment_name

name = get_experiment_name("resnet34", "augmented")
print(name)  # "resnet34_img224_bs32_lr0.001_augmented"
```

#### `validate_config() -> bool`
ì„¤ì • ìœ íš¨ì„± ê²€ì¦

**ë°˜í™˜ê°’**: ì„¤ì •ì´ ìœ íš¨í•˜ë©´ True, ì•„ë‹ˆë©´ False

**ì‚¬ìš© ì˜ˆì œ**:
```python
from config import validate_config

if validate_config():
    print("ì„¤ì •ì´ ìœ íš¨í•©ë‹ˆë‹¤")
else:
    print("ì„¤ì •ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤")
```

---

## ğŸš€ device_utils.py

**ìš©ë„**: í¬ë¡œìŠ¤ í”Œë«í¼ ë””ë°”ì´ìŠ¤ ìµœì í™” ë° í•˜ë“œì›¨ì–´ ê°ì§€

### ì£¼ìš” í•¨ìˆ˜

#### `get_optimal_device() -> Tuple[torch.device, str]`
ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€

**ë°˜í™˜ê°’**: (ë””ë°”ì´ìŠ¤ ê°ì²´, ë””ë°”ì´ìŠ¤ íƒ€ì… ë¬¸ìì—´)

**ì§€ì› ë””ë°”ì´ìŠ¤**:
- **CUDA**: NVIDIA GPU (Linux/Windows)
- **MPS**: Apple Silicon GPU (macOS)
- **CPU**: CPU fallback (ëª¨ë“  í”Œë«í¼)

**ì‚¬ìš© ì˜ˆì œ**:
```python
from device_utils import get_optimal_device

device, device_type = get_optimal_device()
print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device} ({device_type})")

# ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
model = model.to(device)
```

#### `setup_training_device() -> Tuple[torch.device, str]`
í•™ìŠµìš© ë””ë°”ì´ìŠ¤ ì„¤ì • ë° ìµœì í™”

**ë°˜í™˜ê°’**: (ë””ë°”ì´ìŠ¤ ê°ì²´, ë””ë°”ì´ìŠ¤ íƒ€ì… ë¬¸ìì—´)

**ìµœì í™” ê¸°ëŠ¥**:
- **MPS**: Apple Silicon ìµœì í™”, ë©”ëª¨ë¦¬ ì •ë¦¬
- **CUDA**: cuDNN ë²¤ì¹˜ë§ˆí‚¹, ì„±ëŠ¥ ìµœì í™”
- **CPU**: ë©€í‹°ìŠ¤ë ˆë”© ìµœì í™”

**ì‚¬ìš© ì˜ˆì œ**:
```python
from device_utils import setup_training_device

device, device_type = setup_training_device()
# ìë™ìœ¼ë¡œ ìµœì í™” ì„¤ì •ì´ ì ìš©ë¨
```

#### `get_dataloader_config(device_type: str) -> Dict[str, Any]`
ë””ë°”ì´ìŠ¤ íƒ€ì…ì— ë”°ë¥¸ DataLoader ìµœì í™” ì„¤ì •

**ë§¤ê°œë³€ìˆ˜**:
- `device_type`: "MPS", "CUDA", "CPU" ì¤‘ í•˜ë‚˜

**ë°˜í™˜ê°’**: DataLoader ì„¤ì • ë”•ì…”ë„ˆë¦¬

**ìµœì í™” ì „ëµ**:

```python
# MPS (Apple Silicon)
{
    "pin_memory": False,  # MPSëŠ” pin_memory ë¶ˆí•„ìš”
    "num_workers": 0      # ë©€í‹°í”„ë¡œì„¸ì‹± ì´ìŠˆ ë°©ì§€
}

# CUDA (NVIDIA GPU)
{
    "pin_memory": True,   # GPU ë©”ëª¨ë¦¬ ìµœì í™”
    "num_workers": 4-8    # ë³‘ë ¬ ë°ì´í„° ë¡œë”©
}

# CPU
{
    "pin_memory": False,
    "num_workers": 2-4    # ì ë‹¹í•œ ë³‘ë ¬ ì²˜ë¦¬
}
```

**ì‚¬ìš© ì˜ˆì œ**:
```python
from device_utils import setup_training_device, get_dataloader_config
from torch.utils.data import DataLoader

device, device_type = setup_training_device()
dataloader_config = get_dataloader_config(device_type)

train_loader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    **dataloader_config  # ìµœì í™”ëœ ì„¤ì • ì ìš©
)
```

#### `check_gpu_memory(device: torch.device)`
GPU ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸

**ë§¤ê°œë³€ìˆ˜**:
- `device`: í™•ì¸í•  ë””ë°”ì´ìŠ¤

**ê¸°ëŠ¥**:
- **CUDA**: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œì‹œ
- **MPS**: í†µí•© ë©”ëª¨ë¦¬ ì •ë³´ í‘œì‹œ
- **CPU**: ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´ í‘œì‹œ

#### `test_device() -> Tuple[torch.device, str]`
ë””ë°”ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

**ë°˜í™˜ê°’**: (í…ŒìŠ¤íŠ¸ëœ ë””ë°”ì´ìŠ¤, ë””ë°”ì´ìŠ¤ íƒ€ì…)

**í…ŒìŠ¤íŠ¸ ë‚´ìš©**:
- í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
- DataLoader ì„¤ì • ê¶Œì¥ì‚¬í•­ ì¶œë ¥

---

## ğŸ“Š wandb_utils.py

**ìš©ë„**: WandB ì‹¤í—˜ ì¶”ì  ë° ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°

### ì£¼ìš” í•¨ìˆ˜

#### `init_wandb(config: Dict[str, Any], run_name: str = None) -> wandb.Run`
WandB ëŸ° ì´ˆê¸°í™”

**ë§¤ê°œë³€ìˆ˜**:
- `config`: WandB ì„¤ì • ë”•ì…”ë„ˆë¦¬
- `run_name`: ëŸ° ì´ë¦„ (ì„ íƒì‚¬í•­)

**ë°˜í™˜ê°’**: ì´ˆê¸°í™”ëœ WandB ëŸ° ê°ì²´

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import init_wandb
from config import get_wandb_config

config = get_wandb_config()
run = init_wandb(config, run_name="baseline_test")
```

#### `log_metrics(metrics: Dict[str, Any], step: int = None, commit: bool = True)`
ë©”íŠ¸ë¦­ ë¡œê¹…

**ë§¤ê°œë³€ìˆ˜**:
- `metrics`: ë¡œê¹…í•  ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
- `step`: ìŠ¤í… ë²ˆí˜¸ (ì„ íƒì‚¬í•­)
- `commit`: ì¦‰ì‹œ ì»¤ë°‹ ì—¬ë¶€

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import log_metrics

# í•™ìŠµ ë©”íŠ¸ë¦­ ë¡œê¹…
log_metrics({
    'train_loss': 0.5,
    'train_accuracy': 0.85,
    'val_loss': 0.6,
    'val_accuracy': 0.82,
    'epoch': 10
})

# ë°°ì¹˜ë³„ ë©”íŠ¸ë¦­ (ì»¤ë°‹í•˜ì§€ ì•Šê³ )
log_metrics({
    'batch_loss': 0.45
}, commit=False)
```

#### `log_model_info(model, input_shape: tuple = None)`
ëª¨ë¸ ì •ë³´ ìë™ ë¡œê¹…

**ë§¤ê°œë³€ìˆ˜**:
- `model`: PyTorch ëª¨ë¸
- `input_shape`: ì…ë ¥ í…ì„œ ëª¨ì–‘ (ì„ íƒì‚¬í•­)

**ë¡œê¹… ì •ë³´**:
- ëª¨ë¸ í´ë˜ìŠ¤ ì´ë¦„
- ì´ íŒŒë¼ë¯¸í„° ìˆ˜
- í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜
- ëª¨ë¸ ê·¸ë˜í”„ (input_shape ì œê³µ ì‹œ)

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import log_model_info
import timm

model = timm.create_model('resnet34', num_classes=17)
log_model_info(model, input_shape=(3, 224, 224))
```

#### `log_system_info()`
ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹…

**ë¡œê¹… ì •ë³´**:
- Python ë²„ì „
- í”Œë«í¼ ì •ë³´
- PyTorch ë²„ì „
- CUDA ì •ë³´ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
- GPU ì •ë³´

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import log_system_info

# ì‹¤í—˜ ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹…
log_system_info()
```

#### `log_confusion_matrix(y_true, y_pred, class_names: List[str] = None)`
í˜¼ë™ í–‰ë ¬ ì‹œê°í™” ë° ë¡œê¹…

**ë§¤ê°œë³€ìˆ˜**:
- `y_true`: ì‹¤ì œ ë¼ë²¨
- `y_pred`: ì˜ˆì¸¡ ë¼ë²¨
- `class_names`: í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡ (ì„ íƒì‚¬í•­)

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import log_confusion_matrix

# ê²€ì¦ ê²°ê³¼ í˜¼ë™ í–‰ë ¬ ë¡œê¹…
log_confusion_matrix(
    y_true=val_targets,
    y_pred=val_predictions,
    class_names=[f"Class_{i}" for i in range(17)]
)
```

#### `create_run_name(model_name: str, experiment_type: str = None) -> str`
íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ëŸ° ì´ë¦„ ìƒì„±

**ë§¤ê°œë³€ìˆ˜**:
- `model_name`: ëª¨ë¸ ì´ë¦„
- `experiment_type`: ì‹¤í—˜ íƒ€ì… (ì„ íƒì‚¬í•­)

**ë°˜í™˜ê°’**: ìƒì„±ëœ ëŸ° ì´ë¦„

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import create_run_name

run_name = create_run_name("resnet34", "baseline")
print(run_name)  # "resnet34_baseline_1202_1430"
```

#### `save_model_artifact(model_path: str, name: str, type_: str = "model", metadata: Dict = None)`
ëª¨ë¸ì„ WandB ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥

**ë§¤ê°œë³€ìˆ˜**:
- `model_path`: ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
- `name`: ì•„í‹°íŒ©íŠ¸ ì´ë¦„
- `type_`: ì•„í‹°íŒ©íŠ¸ íƒ€ì…
- `metadata`: ë©”íƒ€ë°ì´í„° (ì„ íƒì‚¬í•­)

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import save_model_artifact

save_model_artifact(
    model_path="models/best_model.pth",
    name="best_resnet34",
    metadata={"val_f1": 0.85, "epoch": 25}
)
```

#### `finish_run()`
í˜„ì¬ WandB ëŸ° ì¢…ë£Œ

**ì‚¬ìš© ì˜ˆì œ**:
```python
from wandb_utils import finish_run

try:
    # í•™ìŠµ ì½”ë“œ
    pass
finally:
    finish_run()  # í•­ìƒ ëŸ° ì¢…ë£Œ
```

---

## ğŸ¯ baseline_simple.py

**ìš©ë„**: ë¹ ë¥¸ í™˜ê²½ ê²€ì¦ì„ ìœ„í•œ ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸ ì‹¤í–‰

### ì£¼ìš” í´ë˜ìŠ¤

#### `ImageDataset(Dataset)`
ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤

**ë§¤ê°œë³€ìˆ˜**:
- `csv`: CSV íŒŒì¼ ê²½ë¡œ
- `path`: ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
- `transform`: ë°ì´í„° ë³€í™˜ (ì„ íƒì‚¬í•­)

**ì‚¬ìš© ì˜ˆì œ**:
```python
import albumentations as A
from albumentations.pytorch import ToTensorV2

transform = A.Compose([
    A.Resize(32, 32),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

dataset = ImageDataset(
    csv="data/train.csv",
    path="data/train",
    transform=transform
)
```

### ì£¼ìš” í•¨ìˆ˜

#### `train_one_epoch(loader, model, optimizer, loss_fn, device) -> Dict[str, float]`
í•œ ì—í¬í¬ í•™ìŠµ ì‹¤í–‰

**ë§¤ê°œë³€ìˆ˜**:
- `loader`: ë°ì´í„° ë¡œë”
- `model`: PyTorch ëª¨ë¸
- `optimizer`: ì˜µí‹°ë§ˆì´ì €
- `loss_fn`: ì†ì‹¤ í•¨ìˆ˜
- `device`: ë””ë°”ì´ìŠ¤

**ë°˜í™˜ê°’**: í•™ìŠµ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬

#### `setup_device() -> Tuple[torch.device, Dict[str, Any]]`
í˜¸í™˜ì„± ìš°ì„  ë””ë°”ì´ìŠ¤ ì„¤ì •

**ë°˜í™˜ê°’**: (ë””ë°”ì´ìŠ¤, DataLoader ì„¤ì •)

**íŠ¹ì§•**:
- í˜¸í™˜ì„± ëª¨ë“œ ì§€ì›
- macOS ìµœì í™” ëª¨ë“œ ì§€ì›
- Fallback ë©”ì»¤ë‹ˆì¦˜

#### `main()`
ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜

**ì‹¤í–‰ ê³¼ì •**:
1. ë¡œê¹… ì„¤ì •
2. ë””ë°”ì´ìŠ¤ ì„¤ì •
3. ë°ì´í„° ë¡œë”©
4. ëª¨ë¸ í•™ìŠµ (1 epoch)
5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
6. ê²°ê³¼ ì €ì¥

---

## ğŸš€ train_with_wandb.py

**ìš©ë„**: WandB í†µí•© ê³ ê¸‰ ì‹¤í—˜ ì‹¤í–‰

### ì£¼ìš” í´ë˜ìŠ¤

#### `ImageDataset(Dataset)`
ê³ ê¸‰ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤

**íŠ¹ì§•**:
- í•™ìŠµ/í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì§€ì›
- ê²€ì¦ ì„¸íŠ¸ ë¶„í•  ì§€ì›
- ê³ ê¸‰ ë°ì´í„° ì¦ê°•

### ì£¼ìš” í•¨ìˆ˜

#### `get_transforms(img_size: int, is_train: bool = True) -> A.Compose`
ë°ì´í„° ì¦ê°• ë³€í™˜ ìƒì„±

**ë§¤ê°œë³€ìˆ˜**:
- `img_size`: ì´ë¯¸ì§€ í¬ê¸°
- `is_train`: í•™ìŠµìš© ì—¬ë¶€

**í•™ìŠµìš© ì¦ê°•**:
- ìˆ˜í‰ ë’¤ì§‘ê¸°
- íšŒì „ (Â±15ë„)
- ë°ê¸°/ëŒ€ë¹„ ì¡°ì •
- ì •ê·œí™”

**ê²€ì¦/í…ŒìŠ¤íŠ¸ìš©**:
- í¬ê¸° ì¡°ì •ë§Œ
- ì •ê·œí™”

**ì‚¬ìš© ì˜ˆì œ**:
```python
from train_with_wandb import get_transforms

train_transform = get_transforms(224, is_train=True)
val_transform = get_transforms(224, is_train=False)
```

#### `train_one_epoch(loader, model, optimizer, loss_fn, device, epoch) -> Dict[str, float]`
WandB ë¡œê¹…ì´ í¬í•¨ëœ í•™ìŠµ í•¨ìˆ˜

**ë§¤ê°œë³€ìˆ˜**:
- `loader`: í•™ìŠµ ë°ì´í„° ë¡œë”
- `model`: PyTorch ëª¨ë¸
- `optimizer`: ì˜µí‹°ë§ˆì´ì €
- `loss_fn`: ì†ì‹¤ í•¨ìˆ˜
- `device`: ë””ë°”ì´ìŠ¤
- `epoch`: í˜„ì¬ ì—í¬í¬

**ë°˜í™˜ê°’**: í•™ìŠµ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬

**íŠ¹ì§•**:
- ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
- ë°°ì¹˜ë³„ ë©”íŠ¸ë¦­ ë¡œê¹… (50ë°°ì¹˜ë§ˆë‹¤)
- ì—í¬í¬ë³„ ì •í™•ë„/F1 ìŠ¤ì½”ì–´ ê³„ì‚°

**ì‚¬ìš© ì˜ˆì œ**:
```python
from train_with_wandb import train_one_epoch

metrics = train_one_epoch(
    loader=train_loader,
    model=model,
    optimizer=optimizer,
    loss_fn=criterion,
    device=device,
    epoch=current_epoch
)

print(f"Train Loss: {metrics['train_loss']:.4f}")
print(f"Train Accuracy: {metrics['train_accuracy']:.4f}")
```

#### `validate_one_epoch(loader, model, loss_fn, device, epoch) -> Dict[str, Any]`
ê²€ì¦ ì‹¤í–‰ í•¨ìˆ˜

**ë§¤ê°œë³€ìˆ˜**:
- `loader`: ê²€ì¦ ë°ì´í„° ë¡œë”
- `model`: PyTorch ëª¨ë¸
- `loss_fn`: ì†ì‹¤ í•¨ìˆ˜
- `device`: ë””ë°”ì´ìŠ¤
- `epoch`: í˜„ì¬ ì—í¬í¬

**ë°˜í™˜ê°’**: ê²€ì¦ ë©”íŠ¸ë¦­ ë° ì˜ˆì¸¡ ê²°ê³¼

```python
{
    'val_loss': float,
    'val_accuracy': float,
    'val_f1': float,
    'predictions': np.array,
    'targets': np.array
}
```

**íŠ¹ì§•**:
- ì•ˆì „í•œ ê²€ì¦ (ë¹ˆ ë¡œë” ì²˜ë¦¬)
- í˜¼ë™ í–‰ë ¬ìš© ì˜ˆì¸¡/íƒ€ê²Ÿ ë°˜í™˜
- ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”

#### `predict_test_data(model, device, test_loader, output_file) -> pd.DataFrame`
í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì €ì¥

**ë§¤ê°œë³€ìˆ˜**:
- `model`: í•™ìŠµëœ ëª¨ë¸
- `device`: ë””ë°”ì´ìŠ¤
- `test_loader`: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
- `output_file`: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ

**ë°˜í™˜ê°’**: ì œì¶œìš© DataFrame

**ê¸°ëŠ¥**:
- í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
- ì œì¶œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
- ì˜ˆì¸¡ ë¶„í¬ ì¶œë ¥

**ì‚¬ìš© ì˜ˆì œ**:
```python
from train_with_wandb import predict_test_data

submission_df = predict_test_data(
    model=best_model,
    device=device,
    test_loader=test_loader,
    output_file="submission_20241202.csv"
)
```

#### `train_model()`
ë©”ì¸ í•™ìŠµ í•¨ìˆ˜

**ì‹¤í–‰ ê³¼ì •**:
1. ë¡œê¹… ì„¤ì •
2. ì„¤ì • ê²€ì¦
3. ë””ë°”ì´ìŠ¤ ì„¤ì •
4. WandB ì´ˆê¸°í™”
5. ë°ì´í„° ì¤€ë¹„ (train/val ë¶„í• )
6. ëª¨ë¸ ì„¤ì •
7. í•™ìŠµ ë£¨í”„ ì‹¤í–‰
8. ìµœì  ëª¨ë¸ ì €ì¥
9. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìƒì„±

**íŠ¹ì§•**:
- ì™„ì „ ìë™í™”ëœ ì‹¤í—˜ íŒŒì´í”„ë¼ì¸
- ê²€ì¦ ê¸°ë°˜ ìµœì  ëª¨ë¸ ì €ì¥
- ìƒì„¸í•œ ë¡œê¹… ë° ì§„í–‰ë¥  í‘œì‹œ
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬

---

## ğŸ”¤ train_with_ocr.py

**ìš©ë„**: OCR í†µí•© ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë¶„ë¥˜

### ì£¼ìš” íŠ¹ì§•

**ë©€í‹°ëª¨ë‹¬ ì ‘ê·¼**:
- ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ (CNN)
- í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ (OCR â†’ NLP)
- íŠ¹ì§• ìœµí•© ë° ë¶„ë¥˜

**ì§€ì› OCR ì—”ì§„**:
- **EasyOCR**: ë‹¤êµ­ì–´ ì§€ì›, GPU ê°€ì†
- **Tesseract**: ì „í†µì ì¸ OCR ì—”ì§„

### ì£¼ìš” í´ë˜ìŠ¤

#### `MultimodalDataset(Dataset)`
ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹

**íŠ¹ì§•**:
- OCR í…ìŠ¤íŠ¸ ìë™ ì¶”ì¶œ
- ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ë™ì‹œ ì²˜ë¦¬
- ìºì‹± ë©”ì»¤ë‹ˆì¦˜ (ì„ íƒì‚¬í•­)

#### `MultimodalModel(nn.Module)`
ë©€í‹°ëª¨ë‹¬ ë¶„ë¥˜ ëª¨ë¸

**ì•„í‚¤í…ì²˜**:
```python
# ì´ë¯¸ì§€ ì¸ì½”ë”
image_encoder = timm.create_model('resnet34', pretrained=True)

# í…ìŠ¤íŠ¸ ì¸ì½”ë”  
text_encoder = nn.LSTM(embedding_dim, hidden_dim)

# ìœµí•© ë ˆì´ì–´
fusion_layer = nn.Linear(image_dim + text_dim, hidden_dim)

# ë¶„ë¥˜ê¸°
classifier = nn.Linear(hidden_dim, num_classes)
```

### ì£¼ìš” í•¨ìˆ˜

#### `extract_text_with_ocr(image_path: str, ocr_engine: str = "easyocr") -> str`
ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

**ë§¤ê°œë³€ìˆ˜**:
- `image_path`: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
- `ocr_engine`: "easyocr" ë˜ëŠ” "tesseract"

**ë°˜í™˜ê°’**: ì¶”ì¶œëœ í…ìŠ¤íŠ¸

**ì‚¬ìš© ì˜ˆì œ**:
```python
from train_with_ocr import extract_text_with_ocr

text = extract_text_with_ocr("document.jpg", "easyocr")
print(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {text}")
```

#### `preprocess_text(text: str) -> List[str]`
í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬

**ì „ì²˜ë¦¬ ê³¼ì •**:
- íŠ¹ìˆ˜ë¬¸ì ì œê±°
- ì†Œë¬¸ì ë³€í™˜
- í† í°í™”
- ë¶ˆìš©ì–´ ì œê±°

#### `train_multimodal_model()`
ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í•™ìŠµ

**íŠ¹ì§•**:
- ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ë™ì‹œ í•™ìŠµ
- ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥í•œ ì†ì‹¤ í•¨ìˆ˜
- OCR í’ˆì§ˆì— ë”°ë¥¸ ì ì‘ì  í•™ìŠµ

---

## ğŸ› ï¸ ì‚¬ìš© íŒ¨í„´ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì„¤ì • ê´€ë¦¬ íŒ¨í„´

```python
# 1. ì„¤ì • ë¡œë“œ ë° ê²€ì¦
from config import validate_config, EXPERIMENT_CONFIG, DATA_CONFIG

if not validate_config():
    raise ValueError("ì„¤ì • ì˜¤ë¥˜")

# 2. ë””ë°”ì´ìŠ¤ ì„¤ì •
from device_utils import setup_training_device, get_dataloader_config

device, device_type = setup_training_device()
dataloader_config = get_dataloader_config(device_type)

# 3. WandB ì´ˆê¸°í™”
from wandb_utils import init_wandb, create_run_name
from config import get_wandb_config

run_name = create_run_name("resnet34", "experiment")
wandb_config = get_wandb_config()
run = init_wandb(wandb_config, run_name)
```

### 2. í•™ìŠµ ë£¨í”„ íŒ¨í„´

```python
from wandb_utils import log_metrics, log_model_info, finish_run

try:
    # ëª¨ë¸ ì •ë³´ ë¡œê¹…
    log_model_info(model, input_shape=(3, 224, 224))
    
    for epoch in range(epochs):
        # í•™ìŠµ
        train_metrics = train_one_epoch(...)
        
        # ê²€ì¦
        val_metrics = validate_one_epoch(...)
        
        # ë©”íŠ¸ë¦­ ë¡œê¹…
        log_metrics({
            **train_metrics,
            **val_metrics,
            'epoch': epoch,
            'learning_rate': scheduler.get_last_lr()[0]
        })
        
        # ìµœì  ëª¨ë¸ ì €ì¥
        if val_metrics['val_f1'] > best_f1:
            torch.save(model.state_dict(), 'best_model.pth')
            
finally:
    finish_run()
```

### 3. í¬ë¡œìŠ¤ í”Œë«í¼ DataLoader íŒ¨í„´

```python
from device_utils import setup_training_device, get_dataloader_config

# ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” ì„¤ì • ìë™ ì ìš©
device, device_type = setup_training_device()
dataloader_config = get_dataloader_config(device_type)

train_loader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    **dataloader_config  # í”Œë«í¼ì— ìµœì í™”ëœ ì„¤ì •
)
```

### 4. ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´

```python
import logging
from wandb_utils import finish_run

logger = logging.getLogger(__name__)

try:
    # í•™ìŠµ ì½”ë“œ
    train_model()
    
except Exception as e:
    logger.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    raise
    
finally:
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    finish_run()
    logger.info("ì‹¤í—˜ ì¢…ë£Œ")
```

### 5. OCR í†µí•© íŒ¨í„´

```python
from train_with_ocr import extract_text_with_ocr, MultimodalDataset

# OCR ì„¤ì • í™•ì¸
try:
    import easyocr
    ocr_engine = "easyocr"
except ImportError:
    try:
        import pytesseract
        ocr_engine = "tesseract"
    except ImportError:
        raise ImportError("OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

# ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ìƒì„±
dataset = MultimodalDataset(
    csv_path="data/train.csv",
    image_dir="data/train",
    ocr_engine=ocr_engine,
    cache_text=True  # í…ìŠ¤íŠ¸ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
)
```

---

## ğŸ”§ í™•ì¥ ê°€ì´ë“œ

### ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€

1. **config.py ìˆ˜ì •**:
```python
EXPERIMENT_CONFIG["model_name"] = "efficientnet_b0"
```

2. **ëª¨ë¸ ë¡œë“œ ë¶€ë¶„ ìˆ˜ì •**:
```python
# train_with_wandb.py
model = timm.create_model(
    EXPERIMENT_CONFIG['model_name'],
    pretrained=True,
    num_classes=17
)
```

### ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€

1. **ê³„ì‚° í•¨ìˆ˜ ì •ì˜**:
```python
def calculate_custom_metric(y_true, y_pred):
    # ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­ ê³„ì‚°
    return metric_value
```

2. **ë¡œê¹… ì¶”ê°€**:
```python
custom_metric = calculate_custom_metric(targets, predictions)
log_metrics({'custom_metric': custom_metric})
```

### ìƒˆë¡œìš´ ë°ì´í„° ì¦ê°• ì¶”ê°€

```python
def get_advanced_transforms(img_size):
    return A.Compose([
        A.Resize(img_size, img_size),
        A.HorizontalFlip(p=0.5),
        A.RandomRotate90(p=0.3),
        A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.3),
        # ìƒˆë¡œìš´ ì¦ê°• ê¸°ë²• ì¶”ê°€
        A.Normalize(),
        ToTensorV2()
    ])
```

ì´ ëª¨ë“ˆ ì°¸ì¡° ë¬¸ì„œëŠ” CV-Classify ì‹œìŠ¤í…œì˜ ëª¨ë“  ì£¼ìš” ì»´í¬ë„ŒíŠ¸ì— ëŒ€í•œ ì™„ì „í•œ API ì°¸ì¡°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ì˜ ìš©ë„, ë§¤ê°œë³€ìˆ˜, ë°˜í™˜ê°’, ì‚¬ìš© ì˜ˆì œë¥¼ í¬í•¨í•˜ì—¬ ê°œë°œìê°€ ì‹œìŠ¤í…œì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.