# CV-Classify ê°œë°œì ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” CV-Classify ì‹œìŠ¤í…œì˜ ê°œë°œ, í™•ì¥, ê¸°ì—¬ë¥¼ ìœ„í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤. ì½”ë“œ êµ¬ì¡°, ê°œë°œ ì›Œí¬í”Œë¡œìš°, í™•ì¥ ë°©ë²•, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ—ï¸ ê°œë°œ í™˜ê²½ ì„¤ì •

### ê°œë°œìš© ì„¤ì¹˜

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd cv-classify

# 2. ê°œë°œ ëª¨ë“œ ì„¤ì •
chmod +x setup.sh
./setup.sh

# 3. ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜ (ê°œë°œìš© íŒ¨í‚¤ì§€ í¬í•¨)
pip install -r requirements.txt
pip install black flake8 pytest mypy jupyter

# 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.template .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ WandB API í‚¤ ë“± ì„¤ì •

# 5. ê°œë°œ í™˜ê²½ í™•ì¸
python3 codes/device_utils.py  # ë””ë°”ì´ìŠ¤ í…ŒìŠ¤íŠ¸
./menu.sh                      # ë©”ë‰´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```

### IDE ì„¤ì •

#### VS Code ì„¤ì •

`.vscode/settings.json`:
```json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length", "88"],
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true,
        ".git": true,
        "wandb": true,
        "logs": true
    }
}
```

`.vscode/launch.json`:
```json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Train Baseline",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/codes/baseline_simple.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}/codes"
        },
        {
            "name": "Train with WandB",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/codes/train_with_wandb.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}/codes"
        }
    ]
}
```

---

## ğŸ›ï¸ ì½”ë“œ ì•„í‚¤í…ì²˜

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

#### 1. ëª¨ë“ˆì„± (Modularity)
```python
# ê° ëª¨ë“ˆì€ ë‹¨ì¼ ì±…ì„ì„ ê°€ì§
config.py       â†’ ì„¤ì • ê´€ë¦¬
device_utils.py â†’ í•˜ë“œì›¨ì–´ ì¶”ìƒí™”
wandb_utils.py  â†’ ì‹¤í—˜ ì¶”ì 
```

#### 2. ì˜ì¡´ì„± ì£¼ì… (Dependency Injection)
```python
# í•˜ë“œì½”ë”©ëœ ì˜ì¡´ì„± ëŒ€ì‹  ì£¼ì… ë°›ìŒ
def train_model(config, device_manager, experiment_tracker):
    # ì„¤ì •ê³¼ ì˜ì¡´ì„±ì„ ì™¸ë¶€ì—ì„œ ì£¼ì…
    pass
```

#### 3. í”Œë«í¼ ì¶”ìƒí™” (Platform Abstraction)
```python
# í”Œë«í¼ë³„ ì°¨ì´ë¥¼ ì¶”ìƒí™”
def get_optimal_device():
    # ë‚´ë¶€ì ìœ¼ë¡œ í”Œë«í¼ì„ ê°ì§€í•˜ê³  ìµœì  ì„¤ì • ë°˜í™˜
    pass
```

### ë ˆì´ì–´ë³„ ì—­í• 

#### 1. ì„¤ì • ë ˆì´ì–´ (Configuration Layer)
```python
# config.py
PROJECT_ROOT = Path(__file__).parent.parent

# í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬
WANDB_CONFIG = {...}
EXPERIMENT_CONFIG = {...}  # ì‹¤ì œ ì‹¤í—˜ìš©
BASELINE_CONFIG = {...}    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
```

#### 2. ì¶”ìƒí™” ë ˆì´ì–´ (Abstraction Layer)
```python
# device_utils.py
class DeviceManager:
    def get_optimal_device(self):
        # í”Œë«í¼ë³„ ìµœì  ë””ë°”ì´ìŠ¤ ê°ì§€
    
    def get_dataloader_config(self):
        # ë””ë°”ì´ìŠ¤ì— ë§ëŠ” DataLoader ì„¤ì •
```

#### 3. ìœ í‹¸ë¦¬í‹° ë ˆì´ì–´ (Utility Layer)
```python
# wandb_utils.py
class ExperimentTracker:
    def init_experiment(self, config):
        # ì‹¤í—˜ ì´ˆê¸°í™”
    
    def log_metrics(self, metrics):
        # ë©”íŠ¸ë¦­ ë¡œê¹…
```

#### 4. ì‹¤í–‰ ë ˆì´ì–´ (Execution Layer)
```python
# train_with_wandb.py
def main():
    # 1. ì„¤ì • ë¡œë“œ
    # 2. ë””ë°”ì´ìŠ¤ ì„¤ì •
    # 3. ë°ì´í„° ì¤€ë¹„
    # 4. ëª¨ë¸ í•™ìŠµ
    # 5. ê²°ê³¼ ì €ì¥
```

---

## ğŸ”§ ê°œë°œ ì›Œí¬í”Œë¡œìš°

### Git ë¸Œëœì¹˜ ì „ëµ

```bash
main            # ì•ˆì •ëœ ë°°í¬ ë²„ì „
â”œâ”€â”€ develop     # ê°œë°œ í†µí•© ë¸Œëœì¹˜
â”œâ”€â”€ feature/*   # ìƒˆë¡œìš´ ê¸°ëŠ¥ ê°œë°œ
â”œâ”€â”€ bugfix/*    # ë²„ê·¸ ìˆ˜ì •
â””â”€â”€ hotfix/*    # ê¸´ê¸‰ ìˆ˜ì •
```

#### ë¸Œëœì¹˜ ëª…ëª… ê·œì¹™

```bash
# ê¸°ëŠ¥ ê°œë°œ
feature/add-efficientnet-support
feature/improve-ocr-integration
feature/cross-platform-optimization

# ë²„ê·¸ ìˆ˜ì •
bugfix/fix-mps-memory-leak
bugfix/wandb-connection-error

# í•«í”½ìŠ¤
hotfix/critical-cuda-compatibility
```

### ì»¤ë°‹ ë©”ì‹œì§€ ì»¨ë²¤ì…˜

```bash
# í˜•ì‹: <type>(<scope>): <description>

feat(device): add Apple Silicon MPS support
fix(wandb): resolve API key validation error
docs(readme): update installation instructions
refactor(config): simplify configuration structure
test(device): add cross-platform device tests
perf(dataloader): optimize num_workers for each platform
```

### ê°œë°œ í”„ë¡œì„¸ìŠ¤

#### 1. ìƒˆ ê¸°ëŠ¥ ê°œë°œ

```bash
# 1. ìƒˆ ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/add-new-model

# 2. ê¸°ëŠ¥ êµ¬í˜„
# - ì½”ë“œ ì‘ì„±
# - í…ŒìŠ¤íŠ¸ ì¶”ê°€
# - ë¬¸ì„œ ì—…ë°ì´íŠ¸

# 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -m pytest tests/
./scripts/test_baseline.sh

# 4. ì½”ë“œ í¬ë§·íŒ…
black codes/
flake8 codes/

# 5. ì»¤ë°‹ ë° í‘¸ì‹œ
git add .
git commit -m "feat(model): add EfficientNet support"
git push origin feature/add-new-model

# 6. Pull Request ìƒì„±
```

#### 2. ë²„ê·¸ ìˆ˜ì •

```bash
# 1. ë²„ê·¸ ì¬í˜„
python codes/train_with_wandb.py  # ì˜¤ë¥˜ í™•ì¸

# 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±
# tests/test_bug_reproduction.py

# 3. ìˆ˜ì • êµ¬í˜„
# codes/wandb_utils.py ìˆ˜ì •

# 4. í…ŒìŠ¤íŠ¸ í™•ì¸
python -m pytest tests/test_bug_reproduction.py

# 5. íšŒê·€ í…ŒìŠ¤íŠ¸
./menu.sh  # ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```
tests/
â”œâ”€â”€ unit/                    # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_config.py      # ì„¤ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_device_utils.py # ë””ë°”ì´ìŠ¤ ìœ í‹¸ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_wandb_utils.py  # WandB ìœ í‹¸ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ integration/             # í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_training_pipeline.py
â”‚   â””â”€â”€ test_cross_platform.py
â”œâ”€â”€ e2e/                     # ì—”ë“œíˆ¬ì—”ë“œ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_baseline_execution.py
â”‚   â””â”€â”€ test_full_training.py
â””â”€â”€ fixtures/                # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    â”œâ”€â”€ sample_images/
    â””â”€â”€ mock_configs/
```

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì˜ˆì œ

```python
# tests/unit/test_device_utils.py
import pytest
import torch
from unittest.mock import patch, MagicMock

from codes.device_utils import get_optimal_device, get_dataloader_config


class TestDeviceUtils:
    """ë””ë°”ì´ìŠ¤ ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸"""
    
    @patch('torch.cuda.is_available')
    @patch('torch.backends.mps.is_available')
    def test_cuda_device_selection(self, mock_mps, mock_cuda):
        """CUDA ë””ë°”ì´ìŠ¤ ì„ íƒ í…ŒìŠ¤íŠ¸"""
        mock_cuda.return_value = True
        mock_mps.return_value = False
        
        device, device_type = get_optimal_device()
        
        assert device.type == 'cuda'
        assert device_type == 'CUDA'
    
    @patch('torch.cuda.is_available')
    @patch('torch.backends.mps.is_available')
    def test_mps_device_selection(self, mock_mps, mock_cuda):
        """MPS ë””ë°”ì´ìŠ¤ ì„ íƒ í…ŒìŠ¤íŠ¸"""
        mock_cuda.return_value = False
        mock_mps.return_value = True
        
        device, device_type = get_optimal_device()
        
        assert device.type == 'mps'
        assert device_type == 'MPS'
    
    def test_dataloader_config_cuda(self):
        """CUDA DataLoader ì„¤ì • í…ŒìŠ¤íŠ¸"""
        config = get_dataloader_config('CUDA')
        
        assert config['pin_memory'] == True
        assert config['num_workers'] >= 4
    
    def test_dataloader_config_mps(self):
        """MPS DataLoader ì„¤ì • í…ŒìŠ¤íŠ¸"""
        config = get_dataloader_config('MPS')
        
        assert config['pin_memory'] == False
        assert config['num_workers'] == 0
```

### í†µí•© í…ŒìŠ¤íŠ¸ ì˜ˆì œ

```python
# tests/integration/test_training_pipeline.py
import pytest
import tempfile
import os
from pathlib import Path

from codes.baseline_simple import main as baseline_main
from codes.config import BASELINE_CONFIG


class TestTrainingPipeline:
    """í•™ìŠµ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def temp_data_dir(self):
        """ì„ì‹œ ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
            data_dir = Path(tmpdir) / "data"
            data_dir.mkdir()
            
            # train.csv ìƒì„±
            train_csv = data_dir / "train.csv"
            train_csv.write_text("ID,target\ntest1.jpg,0\ntest2.jpg,1\n")
            
            # test.csv ìƒì„±  
            test_csv = data_dir / "sample_submission.csv"
            test_csv.write_text("ID,target\ntest3.jpg,0\n")
            
            # ì´ë¯¸ì§€ í´ë” ìƒì„±
            (data_dir / "train").mkdir()
            (data_dir / "test").mkdir()
            
            yield data_dir
    
    def test_baseline_execution(self, temp_data_dir, monkeypatch):
        """ë² ì´ìŠ¤ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        # ì„¤ì •ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë³€ê²½
        monkeypatch.setattr('codes.config.DATA_DIR', temp_data_dir)
        monkeypatch.setattr('codes.config.BASELINE_CONFIG.epochs', 1)
        
        # ë² ì´ìŠ¤ë¼ì¸ ì‹¤í–‰ (ì˜¤ë¥˜ ì—†ì´ ì™„ë£Œë˜ì–´ì•¼ í•¨)
        try:
            baseline_main()
            assert True  # ì˜ˆì™¸ ì—†ì´ ì™„ë£Œë¨
        except Exception as e:
            pytest.fail(f"ë² ì´ìŠ¤ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
```

### í¬ë¡œìŠ¤ í”Œë«í¼ í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_cross_platform.py
import pytest
import platform
import subprocess

from codes.device_utils import setup_training_device
from codes.platform_utils import detect_platform


class TestCrossPlatform:
    """í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    
    def test_platform_detection(self):
        """í”Œë«í¼ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        detected = detect_platform()
        current = platform.system().lower()
        
        if current == 'darwin':
            assert detected == 'macos'
        elif current == 'linux':
            assert detected in ['ubuntu', 'centos', 'linux']
        elif current in ['windows', 'cygwin']:
            assert detected == 'windows'
    
    def test_device_setup_cross_platform(self):
        """í¬ë¡œìŠ¤ í”Œë«í¼ ë””ë°”ì´ìŠ¤ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        device, device_type = setup_training_device()
        
        # ëª¨ë“  í”Œë«í¼ì—ì„œ ìœ íš¨í•œ ë””ë°”ì´ìŠ¤ ë°˜í™˜í•´ì•¼ í•¨
        assert device_type in ['CUDA', 'MPS', 'CPU']
        assert hasattr(device, 'type')
    
    @pytest.mark.skipif(
        not subprocess.run(['which', 'bash'], capture_output=True).returncode == 0,
        reason="Bash shell not available"
    )
    def test_shell_script_execution(self):
        """ì…¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        result = subprocess.run(
            ['bash', 'scripts/platform_utils.sh'],
            cwd=Path(__file__).parent.parent.parent,
            capture_output=True,
            text=True
        )
        
        assert result.returncode == 0
        assert "ì‹œìŠ¤í…œ ì •ë³´" in result.stdout
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -m pytest tests/

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ê·¸ë£¹ ì‹¤í–‰
python -m pytest tests/unit/
python -m pytest tests/integration/

# ì»¤ë²„ë¦¬ì§€ í¬í•¨ ì‹¤í–‰
python -m pytest tests/ --cov=codes/ --cov-report=html

# ë§ˆì»¤ë³„ ì‹¤í–‰
python -m pytest -m "not slow"  # ëŠë¦° í…ŒìŠ¤íŠ¸ ì œì™¸
python -m pytest -m "gpu"       # GPU í…ŒìŠ¤íŠ¸ë§Œ
```

---

## ğŸ”Œ í™•ì¥ ê°€ì´ë“œ

### ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€

#### 1. ì„¤ì • ì—…ë°ì´íŠ¸

```python
# codes/config.py
SUPPORTED_MODELS = {
    'resnet34': {
        'family': 'resnet',
        'input_size': 224,
        'memory_multiplier': 1.0
    },
    'efficientnet_b0': {
        'family': 'efficientnet', 
        'input_size': 224,
        'memory_multiplier': 0.8
    },
    'vit_base_patch16_224': {  # ìƒˆ ëª¨ë¸ ì¶”ê°€
        'family': 'transformer',
        'input_size': 224,
        'memory_multiplier': 1.5
    }
}
```

#### 2. ëª¨ë¸ ë¡œë” í™•ì¥

```python
# codes/model_factory.py (ìƒˆ íŒŒì¼ ìƒì„±)
import timm
from typing import Dict, Any

class ModelFactory:
    """ëª¨ë¸ ìƒì„± íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_model(model_name: str, num_classes: int, **kwargs) -> torch.nn.Module:
        """ëª¨ë¸ ìƒì„±"""
        
        if model_name.startswith('vit_'):
            # Vision Transformer íŠ¹ë³„ ì²˜ë¦¬
            model = timm.create_model(
                model_name,
                pretrained=kwargs.get('pretrained', True),
                num_classes=num_classes,
                drop_rate=kwargs.get('drop_rate', 0.1)
            )
        else:
            # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
            model = timm.create_model(
                model_name,
                pretrained=kwargs.get('pretrained', True),
                num_classes=num_classes
            )
        
        return model
    
    @staticmethod
    def get_model_config(model_name: str) -> Dict[str, Any]:
        """ëª¨ë¸ë³„ ê¶Œì¥ ì„¤ì • ë°˜í™˜"""
        from config import SUPPORTED_MODELS
        return SUPPORTED_MODELS.get(model_name, {})
```

#### 3. ê¸°ì¡´ ì½”ë“œ ì—…ë°ì´íŠ¸

```python
# codes/train_with_wandb.py
from model_factory import ModelFactory

# ê¸°ì¡´: model = timm.create_model(...)
# ë³€ê²½:
model = ModelFactory.create_model(
    model_name=EXPERIMENT_CONFIG['model_name'],
    num_classes=EXPERIMENT_CONFIG['num_classes'],
    pretrained=EXPERIMENT_CONFIG['pretrained']
)
```

### ìƒˆë¡œìš´ ë°ì´í„° ì¦ê°• ì¶”ê°€

#### 1. ì¦ê°• ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¥

```python
# codes/augmentation.py (ìƒˆ íŒŒì¼ ìƒì„±)
import albumentations as A
from albumentations.pytorch import ToTensorV2
from typing import List, Dict, Any

class AugmentationFactory:
    """ë°ì´í„° ì¦ê°• íŒ©í† ë¦¬"""
    
    @staticmethod
    def get_transform(
        img_size: int,
        is_train: bool = True,
        augmentation_level: str = 'medium'
    ) -> A.Compose:
        """ì¦ê°• ìˆ˜ì¤€ë³„ ë³€í™˜ ìƒì„±"""
        
        base_transforms = [
            A.Resize(height=img_size, width=img_size),
        ]
        
        if is_train:
            if augmentation_level == 'light':
                train_transforms = [
                    A.HorizontalFlip(p=0.5),
                    A.RandomBrightnessContrast(p=0.2),
                ]
            elif augmentation_level == 'medium':
                train_transforms = [
                    A.HorizontalFlip(p=0.5),
                    A.Rotate(limit=15, p=0.3),
                    A.RandomBrightnessContrast(p=0.3),
                    A.GaussNoise(p=0.2),
                ]
            elif augmentation_level == 'heavy':
                train_transforms = [
                    A.HorizontalFlip(p=0.5),
                    A.Rotate(limit=25, p=0.5),
                    A.RandomBrightnessContrast(p=0.4),
                    A.GaussNoise(p=0.3),
                    A.Cutout(num_holes=8, max_h_size=16, max_w_size=16, p=0.3),
                    A.CoarseDropout(p=0.3),
                ]
            else:
                train_transforms = []
            
            base_transforms.extend(train_transforms)
        
        # ê³µí†µ í›„ì²˜ë¦¬
        base_transforms.extend([
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
        
        return A.Compose(base_transforms)
```

#### 2. ì„¤ì •ì— ì¦ê°• ì˜µì…˜ ì¶”ê°€

```python
# codes/config.py
EXPERIMENT_CONFIG.update({
    'augmentation_level': 'medium',  # light, medium, heavy
    'custom_augmentations': {
        'mixup': False,
        'cutmix': False,
        'autoaugment': False
    }
})
```

### ìƒˆë¡œìš´ ì†ì‹¤ í•¨ìˆ˜ ì¶”ê°€

```python
# codes/losses.py (ìƒˆ íŒŒì¼ ìƒì„±)
import torch
import torch.nn as nn
import torch.nn.functional as F

class FocalLoss(nn.Module):
    """Focal Loss for imbalanced datasets"""
    
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

class LabelSmoothingCrossEntropy(nn.Module):
    """Label Smoothing Cross Entropy"""
    
    def __init__(self, smoothing=0.1):
        super(LabelSmoothingCrossEntropy, self).__init__()
        self.smoothing = smoothing
    
    def forward(self, inputs, targets):
        num_classes = inputs.size(-1)
        log_probs = F.log_softmax(inputs, dim=-1)
        
        targets_one_hot = torch.zeros_like(log_probs).scatter_(
            1, targets.unsqueeze(1), 1
        )
        
        smooth_targets = targets_one_hot * (1 - self.smoothing) + \
                        self.smoothing / num_classes
        
        loss = -(smooth_targets * log_probs).sum(dim=-1)
        return loss.mean()

class LossFactory:
    """ì†ì‹¤ í•¨ìˆ˜ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_loss(loss_type: str, **kwargs):
        if loss_type == 'cross_entropy':
            return nn.CrossEntropyLoss()
        elif loss_type == 'focal':
            return FocalLoss(**kwargs)
        elif loss_type == 'label_smoothing':
            return LabelSmoothingCrossEntropy(**kwargs)
        else:
            raise ValueError(f"Unknown loss type: {loss_type}")
```

### ìƒˆë¡œìš´ ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€

```python
# codes/schedulers.py (ìƒˆ íŒŒì¼ ìƒì„±)
import torch
from torch.optim.lr_scheduler import _LRScheduler
import math

class CosineAnnealingWarmRestarts(_LRScheduler):
    """Cosine Annealing with Warm Restarts"""
    
    def __init__(self, optimizer, T_0, T_mult=1, eta_min=0, last_epoch=-1):
        self.T_0 = T_0
        self.T_i = T_0
        self.T_mult = T_mult
        self.eta_min = eta_min
        self.T_cur = last_epoch
        super(CosineAnnealingWarmRestarts, self).__init__(optimizer, last_epoch)
    
    def get_lr(self):
        return [
            self.eta_min + (base_lr - self.eta_min) * 
            (1 + math.cos(math.pi * self.T_cur / self.T_i)) / 2
            for base_lr in self.base_lrs
        ]
    
    def step(self, epoch=None):
        if epoch is None:
            epoch = self.last_epoch + 1
            self.T_cur = self.T_cur + 1
            if self.T_cur >= self.T_i:
                self.T_cur = self.T_cur - self.T_i
                self.T_i = self.T_i * self.T_mult
        else:
            if epoch >= self.T_0:
                if self.T_mult == 1:
                    self.T_cur = epoch % self.T_0
                    self.T_i = self.T_0
                else:
                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))
                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)
                    self.T_i = self.T_0 * self.T_mult ** (n)
            else:
                self.T_i = self.T_0
                self.T_cur = epoch
        
        self.last_epoch = epoch
        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):
            param_group['lr'] = lr

class SchedulerFactory:
    """ìŠ¤ì¼€ì¤„ëŸ¬ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_scheduler(scheduler_type: str, optimizer, **kwargs):
        if scheduler_type == 'cosine':
            return torch.optim.lr_scheduler.CosineAnnealingLR(
                optimizer, **kwargs
            )
        elif scheduler_type == 'cosine_restart':
            return CosineAnnealingWarmRestarts(
                optimizer, **kwargs
            )
        elif scheduler_type == 'step':
            return torch.optim.lr_scheduler.StepLR(
                optimizer, **kwargs
            )
        elif scheduler_type == 'reduce_plateau':
            return torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, **kwargs
            )
        else:
            raise ValueError(f"Unknown scheduler type: {scheduler_type}")
```

---

## ğŸ¯ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### ì½”ë”© ìŠ¤íƒ€ì¼

#### 1. Python ì½”ë”© í‘œì¤€

```python
# 1. Import ìˆœì„œ
import os                    # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import sys
from pathlib import Path

import torch                 # ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import pandas as pd

from config import CONFIG    # ë¡œì»¬ ëª¨ë“ˆ
from device_utils import setup_device

# 2. í•¨ìˆ˜ ë¬¸ì„œí™”
def train_one_epoch(
    loader: DataLoader,
    model: nn.Module,
    optimizer: torch.optim.Optimizer,
    device: torch.device
) -> Dict[str, float]:
    """
    í•œ ì—í¬í¬ í•™ìŠµ ì‹¤í–‰
    
    Args:
        loader: í•™ìŠµ ë°ì´í„° ë¡œë”
        model: PyTorch ëª¨ë¸
        optimizer: ì˜µí‹°ë§ˆì´ì €
        device: í•™ìŠµ ë””ë°”ì´ìŠ¤
    
    Returns:
        í•™ìŠµ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬ (loss, accuracy, f1)
    
    Raises:
        RuntimeError: CUDA out of memory ë“± ì‹¤í–‰ ì˜¤ë¥˜
    """
    model.train()
    # ... êµ¬í˜„
    
    return {
        'train_loss': avg_loss,
        'train_accuracy': accuracy,
        'train_f1': f1_score
    }

# 3. í´ë˜ìŠ¤ ì„¤ê³„
class ExperimentManager:
    """ì‹¤í—˜ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self._device = None
        self._model = None
    
    @property
    def device(self) -> torch.device:
        """ì§€ì—° ì´ˆê¸°í™”ëœ ë””ë°”ì´ìŠ¤"""
        if self._device is None:
            self._device = self._setup_device()
        return self._device
    
    def _setup_device(self) -> torch.device:
        """private ë©”ì„œë“œëŠ” _ ì ‘ë‘ì‚¬"""
        # ë””ë°”ì´ìŠ¤ ì„¤ì • ë¡œì§
        pass
```

#### 2. ì˜¤ë¥˜ ì²˜ë¦¬

```python
# êµ¬ì²´ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬
def load_model(model_path: str) -> nn.Module:
    """ëª¨ë¸ ë¡œë“œ with ì ì ˆí•œ ì˜ˆì™¸ ì²˜ë¦¬"""
    
    try:
        checkpoint = torch.load(model_path, map_location='cpu')
    except FileNotFoundError:
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    except RuntimeError as e:
        raise RuntimeError(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    try:
        model.load_state_dict(checkpoint['model_state_dict'])
    except KeyError:
        raise ValueError("ì˜ëª»ëœ ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ì…ë‹ˆë‹¤")
    except RuntimeError as e:
        raise ValueError(f"ëª¨ë¸ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return model

# ë¦¬ì†ŒìŠ¤ ì •ë¦¬
def train_with_cleanup():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ ë³´ì¥í•˜ëŠ” í•™ìŠµ í•¨ìˆ˜"""
    
    device = None
    model = None
    
    try:
        device, _ = setup_training_device()
        model = create_model().to(device)
        
        # í•™ìŠµ ì‹¤í–‰
        train_model(model, device)
        
    except Exception as e:
        logger.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    
    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if model is not None:
            del model
        
        if device is not None and device.type == 'cuda':
            torch.cuda.empty_cache()
        elif device is not None and device.type == 'mps':
            torch.mps.empty_cache()
        
        import gc
        gc.collect()
```

#### 3. ë¡œê¹…

```python
import logging
from datetime import datetime

# ë¡œê±° ì„¤ì •
def setup_logger(name: str, level: str = 'INFO') -> logging.Logger:
    """êµ¬ì¡°í™”ëœ ë¡œê±° ì„¤ì •"""
    
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level))
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    file_handler = logging.FileHandler(f"logs/{name}_{timestamp}.log")
    file_handler.setLevel(logging.DEBUG)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # í¬ë§·í„°
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# ì‚¬ìš© ì˜ˆì œ
logger = setup_logger('training')

def train_epoch():
    logger.info("ì—í¬í¬ í•™ìŠµ ì‹œì‘")
    
    try:
        # í•™ìŠµ ë¡œì§
        metrics = train_one_epoch(...)
        logger.info(f"ì—í¬í¬ ì™„ë£Œ: {metrics}")
        
    except Exception as e:
        logger.error(f"ì—í¬í¬ í•™ìŠµ ì‹¤íŒ¨: {e}", exc_info=True)
        raise
```

### ì„±ëŠ¥ ìµœì í™”

#### 1. ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
def optimize_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
    
    # 1. ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… (ë©”ëª¨ë¦¬ vs ê³„ì‚° íŠ¸ë ˆì´ë“œì˜¤í”„)
    if hasattr(model, 'gradient_checkpointing_enable'):
        model.gradient_checkpointing_enable()
    
    # 2. í˜¼í•© ì •ë°€ë„ í•™ìŠµ
    from torch.cuda.amp import autocast, GradScaler
    
    scaler = GradScaler()
    
    for batch in dataloader:
        with autocast():
            outputs = model(batch)
            loss = criterion(outputs, targets)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    
    # 3. ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
    def log_memory_usage():
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            logger.info(f"GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved")
```

#### 2. ë°ì´í„° ë¡œë”© ìµœì í™”

```python
class OptimizedDataset(Dataset):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„°ì…‹"""
    
    def __init__(self, csv_path: str, image_dir: str, cache_images: bool = False):
        self.df = pd.read_csv(csv_path)
        self.image_dir = Path(image_dir)
        self.cache_images = cache_images
        self._image_cache = {} if cache_images else None
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image_path = self.image_dir / row['ID']
        
        # ì´ë¯¸ì§€ ìºì‹± (ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œ ê²½ìš°)
        if self.cache_images and image_path in self._image_cache:
            image = self._image_cache[image_path]
        else:
            image = self._load_image(image_path)
            if self.cache_images:
                self._image_cache[image_path] = image
        
        return image, row['target']
    
    def _load_image(self, path: Path):
        """íš¨ìœ¨ì ì¸ ì´ë¯¸ì§€ ë¡œë”©"""
        try:
            # PILë³´ë‹¤ ë¹ ë¥¸ cv2 ì‚¬ìš© ê³ ë ¤
            import cv2
            image = cv2.imread(str(path))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            return image
        except Exception:
            # fallback to PIL
            from PIL import Image
            return np.array(Image.open(path))
```

### í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„±

```python
def ensure_cross_platform_compatibility():
    """í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„± ë³´ì¥"""
    
    # 1. ê²½ë¡œ ì²˜ë¦¬
    from pathlib import Path
    
    # ì˜ëª»ëœ ë°©ë²•
    # path = "data/train/image.jpg"  # Windowsì—ì„œ ë¬¸ì œ
    
    # ì˜¬ë°”ë¥¸ ë°©ë²•
    path = Path("data") / "train" / "image.jpg"
    
    # 2. í™˜ê²½ ë³€ìˆ˜ ì²˜ë¦¬
    import os
    
    def get_cache_dir():
        if os.name == 'nt':  # Windows
            return Path.home() / "AppData" / "Local" / "cv-classify"
        else:  # Unix-like
            return Path.home() / ".cache" / "cv-classify"
    
    # 3. ë©€í‹°í”„ë¡œì„¸ì‹± í˜¸í™˜ì„±
    if __name__ == '__main__':
        # Windowsì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œ ë°©ì§€
        import multiprocessing
        multiprocessing.set_start_method('spawn', force=True)
```

---

## ğŸ“ ë¬¸ì„œí™” ê°€ì´ë“œ

### ì½”ë“œ ë¬¸ì„œí™”

#### 1. ëª¨ë“ˆ ë¬¸ì„œí™”

```python
"""
CV-Classify Device Utilities

ì´ ëª¨ë“ˆì€ í¬ë¡œìŠ¤ í”Œë«í¼ ë””ë°”ì´ìŠ¤ ê°ì§€ ë° ìµœì í™” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ìë™ ë””ë°”ì´ìŠ¤ ê°ì§€ (CUDA, MPS, CPU)
- í”Œë«í¼ë³„ ìµœì í™” ì„¤ì •
- DataLoader ì„¤ì • ìë™ ì¡°ì •

ì˜ˆì œ:
    >>> from device_utils import setup_training_device
    >>> device, device_type = setup_training_device()
    >>> print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

ì‘ì„±ì: CV-Classify Team
ë²„ì „: 1.0.0
"""

import torch
from typing import Tuple, Dict, Any
```

#### 2. í•¨ìˆ˜ ë¬¸ì„œí™”

```python
def get_dataloader_config(device_type: str) -> Dict[str, Any]:
    """
    ë””ë°”ì´ìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ìµœì í™”ëœ DataLoader ì„¤ì • ë°˜í™˜
    
    ê° í”Œë«í¼ì˜ íŠ¹ì„±ì— ë§ëŠ” DataLoader ì„¤ì •ì„ ì œê³µí•˜ì—¬
    ìµœì ì˜ í•™ìŠµ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        device_type (str): ë””ë°”ì´ìŠ¤ íƒ€ì…
            - "CUDA": NVIDIA GPU
            - "MPS": Apple Silicon GPU  
            - "CPU": CPU ì „ìš©
    
    Returns:
        Dict[str, Any]: DataLoader ì„¤ì • ë”•ì…”ë„ˆë¦¬
            - pin_memory (bool): ë©”ëª¨ë¦¬ ê³ ì • ì‚¬ìš© ì—¬ë¶€
            - num_workers (int): ë³‘ë ¬ ì›Œì»¤ ìˆ˜
            - persistent_workers (bool): ì›Œì»¤ ì¬ì‚¬ìš© ì—¬ë¶€
    
    Raises:
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” device_typeì¸ ê²½ìš°
    
    ì˜ˆì œ:
        >>> config = get_dataloader_config("CUDA")
        >>> dataloader = DataLoader(dataset, **config)
    
    ì°¸ê³ :
        - MPSëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± ì´ìŠˆë¡œ num_workers=0 ê¶Œì¥
        - CUDAëŠ” pin_memory=Trueë¡œ GPU ì „ì†¡ ìµœì í™”
    """
    # êµ¬í˜„...
```

### README ì—…ë°ì´íŠ¸

```markdown
# CV-Classify

## ìƒˆ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ì—…ë°ì´íŠ¸ í•„ìš” ì„¹ì…˜

### ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥ (v1.1.0)
- âœ… EfficientNet ëª¨ë¸ ì§€ì› ì¶”ê°€
- âœ… Focal Loss ì†ì‹¤ í•¨ìˆ˜ ì¶”ê°€  
- âœ… AutoAugment ë°ì´í„° ì¦ê°• ì§€ì›
- âœ… ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë„êµ¬ ì¶”ê°€

### ğŸ“Š ì§€ì› ëª¨ë¸
| ëª¨ë¸ | ì…ë ¥ í¬ê¸° | ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ | ì„±ëŠ¥ |
|------|-----------|---------------|------|
| ResNet34 | 224x224 | 4GB | â­â­â­â­ |
| EfficientNet-B0 | 224x224 | 3GB | â­â­â­â­â­ |
| Vision Transformer | 224x224 | 6GB | â­â­â­â­â­ |

### ğŸ”§ ì‚¬ìš©ë²• ì˜ˆì œ
```bash
# ìƒˆë¡œìš´ ëª¨ë¸ë¡œ í•™ìŠµ
python codes/train_with_wandb.py --model efficientnet_b0

# ì»¤ìŠ¤í…€ ì¦ê°• ë ˆë²¨ ì‚¬ìš©
python codes/train_with_wandb.py --augmentation heavy
```
```

---

## ğŸ”„ CI/CD íŒŒì´í”„ë¼ì¸

### GitHub Actions ì„¤ì •

`.github/workflows/ci.yml`:
```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: [3.8, 3.9, '3.10']
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest black flake8
    
    - name: Run linting
      run: |
        black --check codes/
        flake8 codes/
    
    - name: Run tests
      run: |
        python -m pytest tests/ -v --cov=codes/
    
    - name: Test cross-platform execution
      run: |
        python codes/device_utils.py  # ë””ë°”ì´ìŠ¤ í…ŒìŠ¤íŠ¸
        # bash ìŠ¤í¬ë¦½íŠ¸ëŠ” Windowsì—ì„œ ì œì™¸
        if [ "$RUNNER_OS" != "Windows" ]; then
          bash scripts/platform_utils.sh
        fi
      shell: bash

  integration-test:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Run integration tests
      run: |
        python -m pytest tests/integration/ -v
    
    - name: Test baseline execution
      run: |
        # ì‹¤ì œ ë² ì´ìŠ¤ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ë”ë¯¸ ë°ì´í„°)
        python codes/baseline_simple.py --dry-run

  security-check:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Run security checks
      run: |
        pip install safety bandit
        safety check -r requirements.txt
        bandit -r codes/ -f json
```

### ìë™ ë¦´ë¦¬ìŠ¤ ì„¤ì •

`.github/workflows/release.yml`:
```yaml
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Create Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false
        body: |
          ## ë³€ê²½ì‚¬í•­
          - ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€
          - ë²„ê·¸ ìˆ˜ì •
          - ì„±ëŠ¥ ê°œì„ 
          
          ## ì„¤ì¹˜ ë°©ë²•
          ```bash
          git clone <repo-url>
          cd cv-classify
          git checkout ${{ github.ref }}
          ./setup.sh
          ```
```

---

## ğŸ¯ ì»¨íŠ¸ë¦¬ë·°ì…˜ ê°€ì´ë“œ

### ê¸°ì—¬ í”„ë¡œì„¸ìŠ¤

1. **ì´ìŠˆ ìƒì„±**: ìƒˆ ê¸°ëŠ¥ì´ë‚˜ ë²„ê·¸ ë¦¬í¬íŠ¸
2. **í¬í¬ ìƒì„±**: ê°œì¸ ì €ì¥ì†Œë¡œ í¬í¬
3. **ë¸Œëœì¹˜ ìƒì„±**: ê¸°ëŠ¥ë³„ ë¸Œëœì¹˜ ìƒì„±
4. **ê°œë°œ ì§„í–‰**: ì½”ë“œ ì‘ì„± + í…ŒìŠ¤íŠ¸ ì¶”ê°€
5. **Pull Request**: ì½”ë“œ ë¦¬ë·° ìš”ì²­
6. **ì½”ë“œ ë¦¬ë·°**: í”¼ë“œë°± ë°˜ì˜
7. **ë³‘í•©**: main ë¸Œëœì¹˜ì— ë³‘í•©

### Pull Request í…œí”Œë¦¿

```markdown
## ë³€ê²½ì‚¬í•­ ìš”ì•½
<!-- ì´ PRì—ì„œ ë³€ê²½ëœ ë‚´ìš©ì„ ê°„ëµíˆ ì„¤ëª…í•´ì£¼ì„¸ìš” -->

## ë³€ê²½ íƒ€ì…
- [ ] ë²„ê·¸ ìˆ˜ì •
- [ ] ìƒˆ ê¸°ëŠ¥
- [ ] ì„±ëŠ¥ ê°œì„ 
- [ ] ë¦¬íŒ©í† ë§
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸
- [ ] í…ŒìŠ¤íŠ¸ ì¶”ê°€

## í…ŒìŠ¤íŠ¸ ê²°ê³¼
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í¬ë¡œìŠ¤ í”Œë«í¼ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

## ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ì½”ë“œê°€ í”„ë¡œì íŠ¸ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ë”°ë¦„
- [ ] ì ì ˆí•œ í…ŒìŠ¤íŠ¸ê°€ ì¶”ê°€ë¨
- [ ] ë¬¸ì„œê°€ ì—…ë°ì´íŠ¸ë¨
- [ ] ë¸Œë ˆì´í‚¹ ì²´ì¸ì§€ê°€ ìˆë‹¤ë©´ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ í¬í•¨

## ìŠ¤í¬ë¦°ìƒ·/ë¡œê·¸ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)
<!-- ë³€ê²½ì‚¬í•­ì„ ë³´ì—¬ì£¼ëŠ” ìŠ¤í¬ë¦°ìƒ·ì´ë‚˜ ë¡œê·¸ë¥¼ ì²¨ë¶€í•´ì£¼ì„¸ìš” -->

## ê´€ë ¨ ì´ìŠˆ
Closes #ì´ìŠˆë²ˆí˜¸
```

### ì½”ë“œ ë¦¬ë·° ê°€ì´ë“œë¼ì¸

#### ë¦¬ë·°ì–´ë¥¼ ìœ„í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## ì½”ë“œ ë¦¬ë·° ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ëŠ¥ì„±
- [ ] ì½”ë“œê°€ ì˜ë„í•œ ëŒ€ë¡œ ì‘ë™í•˜ëŠ”ê°€?
- [ ] ì—£ì§€ ì¼€ì´ìŠ¤ê°€ ì ì ˆíˆ ì²˜ë¦¬ë˜ëŠ”ê°€?
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ì´ ì ì ˆí•œê°€?

### ì„±ëŠ¥
- [ ] ì„±ëŠ¥ìƒ ë¬¸ì œê°€ ì—†ëŠ”ê°€?
- [ ] ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±ì€ ì—†ëŠ”ê°€?
- [ ] ë¶ˆí•„ìš”í•œ ê³„ì‚°ì´ ì—†ëŠ”ê°€?

### ë³´ì•ˆ
- [ ] ë³´ì•ˆ ì·¨ì•½ì ì´ ì—†ëŠ”ê°€?
- [ ] ì…ë ¥ ê²€ì¦ì´ ì ì ˆí•œê°€?
- [ ] ë¯¼ê°í•œ ì •ë³´ê°€ ë…¸ì¶œë˜ì§€ ì•ŠëŠ”ê°€?

### ì½”ë“œ í’ˆì§ˆ
- [ ] ì½”ë“œê°€ ì½ê¸° ì‰¬ìš´ê°€?
- [ ] ë„¤ì´ë°ì´ ëª…í™•í•œê°€?
- [ ] ì¤‘ë³µ ì½”ë“œê°€ ì—†ëŠ”ê°€?
- [ ] ì£¼ì„ì´ ì ì ˆí•œê°€?

### í…ŒìŠ¤íŠ¸
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ê°€ ì¶©ë¶„í•œê°€?
- [ ] í…ŒìŠ¤íŠ¸ê°€ ì˜ë¯¸ ìˆëŠ”ê°€?
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í•˜ëŠ”ê°€?

### ë¬¸ì„œí™”
- [ ] API ë¬¸ì„œê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ê°€?
- [ ] READMEê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ê°€?
- [ ] ë³€ê²½ì‚¬í•­ì´ ì ì ˆíˆ ë¬¸ì„œí™”ë˜ì—ˆëŠ”ê°€?
```

### ì´ìŠˆ í…œí”Œë¦¿

#### ë²„ê·¸ ë¦¬í¬íŠ¸

```markdown
---
name: ë²„ê·¸ ë¦¬í¬íŠ¸
about: ë²„ê·¸ë¥¼ ë°œê²¬í–ˆì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”
labels: bug
---

## ë²„ê·¸ ì„¤ëª…
ë²„ê·¸ì— ëŒ€í•œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ì„¤ëª…

## ì¬í˜„ ë°©ë²•
1. '...' ë¡œ ì´ë™
2. '...' í´ë¦­
3. '...' ê¹Œì§€ ìŠ¤í¬ë¡¤
4. ì˜¤ë¥˜ í™•ì¸

## ì˜ˆìƒ ë™ì‘
ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚  ê²ƒìœ¼ë¡œ ì˜ˆìƒí–ˆëŠ”ì§€ ì„¤ëª…

## ì‹¤ì œ ë™ì‘
ì‹¤ì œë¡œ ë¬´ì—‡ì´ ì¼ì–´ë‚¬ëŠ”ì§€ ì„¤ëª…

## ìŠ¤í¬ë¦°ìƒ·
í•´ë‹¹í•˜ëŠ” ê²½ìš° ìŠ¤í¬ë¦°ìƒ· ì²¨ë¶€

## í™˜ê²½ ì •ë³´
- OS: [ì˜ˆ: macOS, Ubuntu]
- Python ë²„ì „: [ì˜ˆ: 3.9]
- GPU: [ì˜ˆ: NVIDIA RTX 3080, Apple M1]
- ê¸°íƒ€ ê´€ë ¨ ì •ë³´

## ì¶”ê°€ ì •ë³´
ë²„ê·¸ì— ëŒ€í•œ ê¸°íƒ€ ì¶”ê°€ ì •ë³´
```

#### ê¸°ëŠ¥ ìš”ì²­

```markdown
---
name: ê¸°ëŠ¥ ìš”ì²­
about: ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì œì•ˆí•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”
labels: enhancement
---

## ê¸°ëŠ¥ ì„¤ëª…
ì›í•˜ëŠ” ê¸°ëŠ¥ì— ëŒ€í•œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ì„¤ëª…

## ë¬¸ì œì 
ì´ ê¸°ëŠ¥ì´ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?

## ì œì•ˆí•˜ëŠ” í•´ê²°ì±…
ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í•´ê²°í•˜ê³  ì‹¶ì€ì§€ ì„¤ëª…

## ëŒ€ì•ˆ
ê³ ë ¤í•´ë³¸ ë‹¤ë¥¸ ëŒ€ì•ˆë“¤ì´ ìˆë‹¤ë©´ ì„¤ëª…

## ì¶”ê°€ ì •ë³´
ê¸°ëŠ¥ ìš”ì²­ì— ëŒ€í•œ ê¸°íƒ€ ì¶”ê°€ ì •ë³´, ìŠ¤í¬ë¦°ìƒ·, ì°¸ê³  ìë£Œ ë“±
```

---

## ğŸ”š ë§ˆë¬´ë¦¬

ì´ ê°œë°œì ê°€ì´ë“œëŠ” CV-Classify ì‹œìŠ¤í…œì˜ ê°œë°œ, í™•ì¥, ê¸°ì—¬ë¥¼ ìœ„í•œ ì¢…í•©ì ì¸ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™**:
- **ëª¨ë“ˆì„±**: ë…ë¦½ì ì´ê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°
- **í’ˆì§ˆ**: í…ŒìŠ¤íŠ¸ì™€ ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•œ í’ˆì§ˆ ë³´ì¥
- **ë¬¸ì„œí™”**: ëª…í™•í•˜ê³  ìµœì‹ ì˜ ë¬¸ì„œ ìœ ì§€

**ê°œë°œ ì›Œí¬í”Œë¡œìš°**:
1. ì´ìŠˆ ìƒì„± â†’ ë¸Œëœì¹˜ ìƒì„± â†’ ê°œë°œ â†’ í…ŒìŠ¤íŠ¸ â†’ PR â†’ ë¦¬ë·° â†’ ë³‘í•©

**í™•ì¥ ê°€ì´ë“œ**:
- ìƒˆë¡œìš´ ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€ ë°©ë²•
- íŒ©í† ë¦¬ íŒ¨í„´ì„ í†µí•œ í™•ì¥ì„± í™•ë³´
- í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„± ìœ ì§€

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ CV-Classify ì‹œìŠ¤í…œì„ íš¨ê³¼ì ìœ¼ë¡œ ê°œë°œí•˜ê³  ë°œì „ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.